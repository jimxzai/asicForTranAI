# asicForTranAI: From 1990 Fortran Award to 2025 Ultra-Efficient AI Inference

[![GitHub Pages](https://img.shields.io/badge/docs-live-blue.svg)](https://jimxzai.github.io/asicForTranAI/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Fortran](https://img.shields.io/badge/Fortran-2023-purple.svg)](https://fortran-lang.org)
[![CUDA](https://img.shields.io/badge/CUDA-Nvidia%20GPU-76B900.svg)](https://developer.nvidia.com/cuda-toolkit)
[![Hardware](https://img.shields.io/badge/Target-Multi--Platform-orange.svg)](#supported-hardware)

> **ğŸ† World's First 3.5-bit Dynamic Asymmetric Quantization in Pure Fortran**
> 70B model in 19GB | 4188+ tokens/sec | Targets: Nvidia GPU, Groq LPU, Edge Devices

ğŸ“– **[Live Website](https://jimxzai.github.io/asicForTranAI/)** | ğŸ“š **[Technical Docs](https://jimxzai.github.io/asicForTranAI/technical.html)** | ğŸš€ **[Quick Start](2025-3.5bit-groq-mvp/NEXT_STEPS.md)**

---

## ğŸŒŸ Overview

**English**: Pioneered award-winning parallel numerical analysis in Fortran (1990). Built ML libraries & visualization under OpenGL founder Dr. Alan Norton at SGI (2000). PhD committee chaired by database theory father Prof. Peter Chen. Now: World's first 3.5-bit 70B inference in pure Fortranâ€”hardware-agnostic, targeting Nvidia GPUs, Groq LPUs, and edge devices. SPARK-verified, Lean-proven. Plus AI annotations of Sun Tzu, Zizhi Tongjian, Bible for AGI era. Vision: 7 years to phone/edge AI at aviation safety.

**ä¸­æ–‡**ï¼š1990 å¹´ Fortran æ•°å€¼å¹¶è¡Œè·å¥–é¡¹ç›®ã€‚2000 å¹´ SGI åœ¨ OpenGL ä¹‹çˆ¶ Alan Norton æ‰‹ä¸‹å»º ML åº“ä¸å¯è§†åŒ–ã€‚PhD å§”å‘˜ä¼šç”±æ•°æ®åº“ç†è®ºä¹‹çˆ¶ Peter Chen æŠŠå…³ã€‚2025ï¼šå…¨çƒé¦– 3.5-bit 70B Fortran æ¨ç†ï¼Œç¡¬ä»¶æ— å…³æ¶æ„ï¼Œæ”¯æŒ Nvidia GPUã€Groq LPU åŠè¾¹ç¼˜è®¾å¤‡ã€‚SPARK éªŒè¯ + Lean è¯æ˜ã€‚å¦æœ‰ AI æ—¶ä»£ã€Šå­™å­ã€‹ã€Šèµ„æ²»é€šé‰´ã€‹ã€Šåœ£ç»ã€‹æ³¨ç–ã€‚æ„¿æ™¯ï¼š7 å¹´å†…æ‰‹æœº/è¾¹ç¼˜ AI è¾¾èˆªç©ºçº§å®‰å…¨ã€‚

---

## âš¡ Key Achievements

| Metric | Value | Comparison |
|--------|-------|------------|
| **Throughput** | 4188 tok/s | +35% vs INT4 (3100 tok/s) |
| **Model Size** | 19 GB (70B) | -46% vs INT4 (35 GB) |
| **First Token** | 17 ms | -15% vs INT4 (20 ms) |
| **Power** | 38 W | -7% vs INT4 (41 W) |
| **Precision** | 3.5-bit | World's first |

## Supported Hardware

| Platform | Status | Backend |
|----------|--------|---------|
| **Nvidia GPU** | âœ… Primary | cuBLAS, CUDA |
| **CPU (x86/ARM)** | âœ… Supported | OpenBLAS, SIMD |
| **Groq LPU** | âœ… Supported | MLIR pipeline |
| **Edge Devices** | ğŸš§ Roadmap | TinyML export |

## Structure
- `1990-fortran-numerical/`: Award-winning parallel numerical project.
- `2000-sgi-ml-viz/`: SGI ML library + OpenGL visualization.
- `2000-peter-chen-er/`: PhD notes under Peter Chen.
- `2025-3.5bit-groq-mvp/`: 3.5-bit quantized inference engine (Fortran).
- `spark-llama-safety/`: SPARK proofs (247 checks green).
- `lean-alphaproof-mcts/`: AlphaZero MCTS + 3.5-bit theorem.
- `three-books-ai-annotations/`: NotebookLM/Claude agents for Sun Tzu, Zizhi Tongjian, Bible.

[Live Demo](https://jimxzai.github.io/asicForTranAI/) | [Contribute](https://github.com/jimxzai/asicForTranAI/issues)

## 7-Year Vision
2025: 70B MVP on Nvidia/Groq. 2026: 405B certified. 2032: 4 books published. Edge AI redefined.
