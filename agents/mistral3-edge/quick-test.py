#!/usr/bin/env python3
"""
Quick Test - å¿«é€ŸéªŒè¯ Mistral 3 Edge Agent åŸºç¡€è®¾æ–½
ç”¨æ³•ï¼špython quick-test.py

æµ‹è¯•å†…å®¹ï¼š
1. Ollama å®‰è£…æ£€æŸ¥
2. å¯ç”¨æ¨¡å‹æ£€æµ‹
3. ç®€çŸ­æ¨ç†æµ‹è¯•ï¼ˆ100å­—è¾“å‡ºï¼Œ<30ç§’ï¼‰
"""

import subprocess
import sys
from pathlib import Path

def test_ollama():
    """æµ‹è¯•1ï¼šOllama å®‰è£…"""
    print("=" * 60)
    print("æµ‹è¯•1ï¼šOllama å®‰è£…æ£€æŸ¥")
    print("=" * 60)

    try:
        result = subprocess.run(
            ["ollama", "--version"],
            capture_output=True,
            text=True,
            timeout=5
        )

        if result.returncode == 0:
            version = result.stdout.strip()
            print(f"âœ… {version}")

            if "0.13.0" in version:
                print("âš ï¸  éœ€è¦ v0.13.1+ æ‰èƒ½ä½¿ç”¨ Ministral 3")
                print("ğŸ’¡ å½“å‰ä½¿ç”¨å¤‡é€‰æ¨¡å‹æµ‹è¯•")

            return True
        else:
            print("âŒ Ollama æœªæ­£ç¡®å®‰è£…")
            return False

    except FileNotFoundError:
        print("âŒ Ollama æœªå®‰è£…")
        print("è¯·è®¿é—®: https://ollama.com/download")
        return False

def test_models():
    """æµ‹è¯•2ï¼šå¯ç”¨æ¨¡å‹"""
    print()
    print("=" * 60)
    print("æµ‹è¯•2ï¼šå¯ç”¨æ¨¡å‹æ£€æµ‹")
    print("=" * 60)

    try:
        result = subprocess.run(
            ["ollama", "list"],
            capture_output=True,
            text=True,
            timeout=10
        )

        if result.returncode != 0:
            print("âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
            return []

        lines = result.stdout.strip().split('\n')
        if len(lines) <= 1:
            print("âŒ æ²¡æœ‰å·²å®‰è£…çš„æ¨¡å‹")
            return []

        models = []
        for line in lines[1:]:
            parts = line.split()
            if parts:
                models.append(parts[0])

        print(f"âœ… æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹:")
        for model in models:
            marker = "ğŸ¯" if "ministral" in model.lower() else "ğŸ“¦"
            print(f"   {marker} {model}")

        return models

    except Exception as e:
        print(f"âŒ æ£€æµ‹å¤±è´¥: {e}")
        return []

def test_quick_inference(models):
    """æµ‹è¯•3ï¼šå¿«é€Ÿæ¨ç†ï¼ˆ100å­—è¾“å‡ºï¼‰"""
    print()
    print("=" * 60)
    print("æµ‹è¯•3ï¼šå¿«é€Ÿæ¨ç†æµ‹è¯•")
    print("=" * 60)

    if not models:
        print("âŒ æ— å¯ç”¨æ¨¡å‹")
        return False

    # é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
    model = models[0]
    print(f"ä½¿ç”¨æ¨¡å‹: {model}")
    print()

    # ç®€çŸ­æç¤ºè¯ï¼ˆåªè¦100å­—è¾“å‡ºï¼‰
    prompt = """è¯·ç”¨100å­—ç®€è¦è§£é‡Šã€Šå­™å­å…µæ³•ã€‹ä¸­"çŸ¥å½¼çŸ¥å·±ï¼Œç™¾æˆ˜ä¸æ®†"åœ¨2025å¹´AIé¢†åŸŸçš„åº”ç”¨ã€‚
ç›´æ¥è¾“å‡ºç­”æ¡ˆï¼Œæ— éœ€é¢å¤–æ ¼å¼ã€‚"""

    print("ğŸ“ æç¤ºè¯: è§£é‡Š'çŸ¥å½¼çŸ¥å·±'åœ¨AIé¢†åŸŸçš„åº”ç”¨ï¼ˆ100å­—ï¼‰")
    print("â³ é¢„è®¡ 10-30 ç§’...")
    print()

    try:
        process = subprocess.Popen(
            ["ollama", "run", model],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )

        # çŸ­è¶…æ—¶ï¼ˆ90ç§’ï¼‰ï¼Œå› ä¸ºåªè¦100å­—
        stdout, stderr = process.communicate(input=prompt, timeout=90)

        if process.returncode != 0:
            print(f"âŒ æ¨ç†å¤±è´¥: {stderr}")
            return False

        print("âœ… æ¨ç†æˆåŠŸï¼")
        print()
        print("=" * 60)
        print("è¾“å‡ºé¢„è§ˆï¼š")
        print("=" * 60)
        print(stdout.strip()[:500])  # åªæ˜¾ç¤ºå‰500å­—ç¬¦
        print()

        return True

    except subprocess.TimeoutExpired:
        process.kill()
        print("âŒ æ¨ç†è¶…æ—¶ï¼ˆ90ç§’ï¼‰")
        print("ğŸ’¡ è¿™å¯èƒ½æ˜¯æ¨ç†æ¨¡å‹ï¼ˆå¦‚ DeepSeek-R1ï¼‰ï¼Œå»ºè®®ç­‰å¾… Mistral 3")
        return False

    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        return False

def main():
    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  Mistral 3 Edge Agent - å¿«é€Ÿæµ‹è¯•                          â•‘")
    print("â•‘  éªŒè¯åŸºç¡€è®¾æ–½æ˜¯å¦å°±ç»ª                                      â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()

    # æµ‹è¯•1ï¼šOllama
    if not test_ollama():
        print()
        print("âŒ æµ‹è¯•å¤±è´¥ï¼šOllama æœªæ­£ç¡®å®‰è£…")
        sys.exit(1)

    # æµ‹è¯•2ï¼šæ¨¡å‹
    models = test_models()

    # æµ‹è¯•3ï¼šæ¨ç†
    success = test_quick_inference(models)

    # æ€»ç»“
    print()
    print("=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)

    if success:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print()
        print("ğŸš€ ä¸‹ä¸€æ­¥ï¼š")
        print("1. è¿è¡Œå®Œæ•´ Agent:")
        print("   python agents/mistral3-edge/mistral3-edge-agent.py \"ä½ çš„å¿ƒå¾—...\"")
        print()
        print("2. ï¼ˆæ¨èï¼‰å‡çº§ Ollama åˆ° v0.13.1+ ä»¥ä½¿ç”¨ Ministral 3:")
        print("   https://github.com/ollama/ollama/releases")
        print()
        print("3. æˆ–æ‹‰å–å¤‡é€‰æ¨¡å‹ï¼ˆå¦‚æœå½“å‰æ¨¡å‹è¾ƒæ…¢ï¼‰:")
        print("   ollama pull ministral-3:3b  # æ›´å¿«ï¼ˆéœ€ v0.13.1+ï¼‰")
        print()
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print()
        print("å¯èƒ½åŸå› ï¼š")
        print("- å½“å‰æ¨¡å‹æ˜¯æ¨ç†å‹ï¼ˆDeepSeek-R1ï¼‰ï¼Œå¤„ç†æ…¢")
        print("- éœ€è¦å‡çº§ Ollama åˆ° v0.13.1+ ä½¿ç”¨ Ministral 3")
        print()
        print("å»ºè®®ï¼š")
        print("1. ç­‰å¾… Ollama v0.13.1 æ­£å¼ç‰ˆ")
        print("2. æˆ–ä½¿ç”¨é¢„è§ˆç‰ˆ: https://github.com/ollama/ollama/releases")

    print()

if __name__ == "__main__":
    main()
