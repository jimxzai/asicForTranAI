#!/usr/bin/env python3
"""
Daily Three-Books Agent - Ministral-3 LOCAL (Ollama)
ç”¨æ³•ï¼špython daily-annotation-ollama.py "ä»Šå¤©è¯»ã€Šå­™å­Â·å§‹è®¡ç¯‡ã€‹â€¦â€¦"

æœ¬åœ°è¿è¡Œï¼Œå®Œå…¨å…è´¹ï¼Œæ— éœ€API keyï¼Œæ•°æ®ä¸å‡ºä½ çš„æœºå™¨ã€‚

Author: Jim Xiao
Date: 2025-12-03
Model: ministral-3:8b (or any Ollama model)
Speed: 80-200 tok/s on RTX 4090, 30-80 tok/s on M2/M3 Mac
"""

import os
import sys
import json
import subprocess
from datetime import datetime
from pathlib import Path

# Repository paths
REPO_ROOT = Path(__file__).parent.parent.parent
ANNOTATIONS_DIR = REPO_ROOT / "three-books-ai-annotations"
DRAFTS_DIR = REPO_ROOT / "books-ai-publishing" / "drafts"

# Default model (can be changed)
DEFAULT_MODEL = "ministral-3:8b"  # Change to "llama3.3:70b" or others if you prefer


def check_ollama():
    """æ£€æŸ¥Ollamaæ˜¯å¦å®‰è£…å¹¶è¿è¡Œ"""
    try:
        result = subprocess.run(
            ["ollama", "list"],
            capture_output=True,
            text=True,
            timeout=5
        )
        return result.returncode == 0
    except (subprocess.TimeoutExpired, FileNotFoundError):
        return False


def call_ollama(prompt: str, model: str = DEFAULT_MODEL) -> str:
    """è°ƒç”¨æœ¬åœ°Ollamaæ¨¡å‹"""

    if not check_ollama():
        print("âŒ Ollamaæœªå®‰è£…æˆ–æœªè¿è¡Œ")
        print("å®‰è£…: https://ollama.com/download")
        print("ç„¶åè¿è¡Œ: ollama pull ministral-3:8b")
        sys.exit(1)

    print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨æœ¬åœ°æ¨¡å‹: {model}")
    print("ğŸ’» å®Œå…¨æœ¬åœ°è¿è¡Œï¼Œæ•°æ®ä¸å‡ºä½ çš„æœºå™¨")
    print()

    try:
        # Use subprocess to call ollama
        process = subprocess.Popen(
            ["ollama", "run", model],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )

        stdout, stderr = process.communicate(input=prompt, timeout=180)

        if process.returncode != 0:
            print(f"âŒ Ollamaé”™è¯¯: {stderr}")
            sys.exit(1)

        return stdout.strip()

    except subprocess.TimeoutExpired:
        print("âŒ ç”Ÿæˆè¶…æ—¶ï¼ˆ3åˆ†é’Ÿï¼‰ï¼Œè¯·é‡è¯•")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è°ƒç”¨Ollamaå¤±è´¥: {e}")
        sys.exit(1)


def generate_annotation(user_note: str, model: str = DEFAULT_MODEL) -> tuple[str, dict]:
    """ç”ŸæˆAIæ³¨ç–"""

    prompt = f"""ä½ ç°åœ¨æ˜¯ã€ŒAIæ—¶ä»£ä¸‰ä¹¦æ³¨ç–å¤§å¸ˆã€ï¼Œä»»åŠ¡æ˜¯ï¼š

1. **è‡ªåŠ¨åˆ†ç±»**: åˆ¤æ–­ç”¨æˆ·å¿ƒå¾—å±äºã€Šå­™å­å…µæ³•ã€‹ã€Šèµ„æ²»é€šé‰´ã€‹ã€Šåœ£ç»ã€‹ä¸­çš„å“ªä¸€éƒ¨ã€å“ªä¸€ç¯‡/å·/ç« 
2. **æ£€ç´¢åŸæ–‡**: å¼•ç”¨ç›¸å…³åŸæ–‡ï¼ˆä¸­è‹±å¯¹ç…§ï¼‰
3. **å†ä»£æ³¨ç–**: å¼•ç”¨ç»å…¸æ³¨ç–ï¼ˆå¦‚æ›¹æ“æ³¨ã€æœç‰§æ³¨ã€èƒ¡ä¸‰çœæ³¨ã€é©¬ä¸Â·è·¯å¾·æ³¨é‡Šç­‰ï¼‰
4. **æ·±åº¦è§£è¯»**: ç”Ÿæˆ2000-3000å­—ä¸­è‹±åŒè¯­æ·±åº¦æ³¨ç–
5. **AIæˆ˜ä¾‹å¯¹ç…§**: åŠ å…¥2025å¹´AIåšå¼ˆå®ä¾‹ï¼ˆå¦‚ Groq vs Nvidiaã€xAI vs OpenAIã€Ministral 3è¾¹ç¼˜éƒ¨ç½²é©å‘½ï¼‰

## ç”¨æˆ·ä»Šæ—¥å¿ƒå¾—ï¼š

{user_note}

## è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š

è¯·ä»¥ Markdown æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

# [ä¹¦å]Â·[ç¯‡ç« å] - AIæ—¶ä»£æ³¨ç–

**æ—¥æœŸ**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}
**åˆ†ç±»**: [å­™å­/èµ„æ²»/åœ£ç»] > [å…·ä½“ç¯‡ç« ]
**å¼•æ“**: Ministral-3 æœ¬åœ°æ¨ç†

## ä¸€ã€åŸæ–‡å¼•ç”¨

[ä¸­æ–‡åŸæ–‡]

[English Translation]

## äºŒã€å†ä»£æ³¨ç–ç²¾é€‰

[å¼•ç”¨2-3æ¡ç»å…¸æ³¨ç–ï¼Œæ³¨æ˜å‡ºå¤„]

## ä¸‰ã€æ·±åº¦è§£è¯»

[ä½ çš„2000å­—åˆ†æï¼Œä¸­è‹±åŒè¯­]

## å››ã€2025 AIæ—¶ä»£å¯¹ç…§

[æ˜ å°„åˆ°å½“å‰AIæˆ˜å±€çš„å…·ä½“æ¡ˆä¾‹]

### æˆ˜ä¾‹åˆ†æ
- **Ministral 3é©å‘½**: Apache 2.0å¼€æºï¼Œè¾¹ç¼˜éƒ¨ç½²æœ€ä½³æ€§ä»·æ¯”
- **Groq vs Nvidia**: LPUä¸“ç”¨æ¨ç†vsé€šç”¨GPU
- **xAI vs OpenAI**: Grokå¼€æºvs GPTé—­æº
- **è¾¹ç¼˜ASIC**: æ‰‹æœº/æ±½è½¦/å«æ˜ŸAIæ¨ç†çš„æœªæ¥

## äº”ã€å¯ç¤ºä¸æ€è€ƒ

[æ€»ç»“æ€§æ€è€ƒï¼Œ300å­—]

---

**æ ‡ç­¾**: #ä¸‰ä¹¦æ³¨ç– #AIæ—¶ä»£ #Ministral3æœ¬åœ°

è¯·ç›´æ¥è¾“å‡ºå®Œæ•´çš„Markdownå†…å®¹ã€‚"""

    result = call_ollama(prompt, model)

    # å…ƒæ•°æ®
    metadata = {
        "date": datetime.now().isoformat(),
        "model": model,
        "engine": "Ollama (Local)",
        "user_note_length": len(user_note),
        "output_length": len(result)
    }

    return result, metadata


def save_annotation(content: str, metadata: dict) -> Path:
    """ä¿å­˜æ³¨ç–åˆ°æ–‡ä»¶"""

    ANNOTATIONS_DIR.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y-%m-%d")
    filename = f"{timestamp}-ai-annotation-local.md"
    filepath = ANNOTATIONS_DIR / filename

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)
        f.write("\n\n---\n\n")
        f.write(f"<!-- Metadata: {json.dumps(metadata, ensure_ascii=False)} -->\n")

    return filepath


def save_draft(user_note: str) -> Path:
    """ä¿å­˜åŸå§‹å¿ƒå¾—"""

    DRAFTS_DIR.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y-%m-%d")
    filename = f"{timestamp}-draft.md"
    filepath = DRAFTS_DIR / filename

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(f"# æ¯æ—¥ä¸‰ä¹¦å¿ƒå¾— - {timestamp}\n\n")
        f.write(user_note)
        f.write("\n")

    return filepath


def main():
    print("=" * 70)
    print("  ä¸‰ä¹¦AIæ³¨ç–ç³»ç»Ÿ - Ministral-3 æœ¬åœ°å¼•æ“ (Ollama)")
    print("  ã€Šå­™å­å…µæ³•ã€‹ã€Šèµ„æ²»é€šé‰´ã€‹ã€Šåœ£ç»ã€‹AIæ—¶ä»£è§£è¯»")
    print("  ğŸš€ å®Œå…¨æœ¬åœ°è¿è¡Œï¼Œæ•°æ®ä¸å‡ºä½ çš„æœºå™¨ï¼Œå®Œå…¨å…è´¹")
    print("=" * 70)
    print()

    # æ£€æŸ¥Ollama
    if not check_ollama():
        print("âŒ Ollamaæœªå®‰è£…æˆ–æœªè¿è¡Œ")
        print()
        print("å¿«é€Ÿå®‰è£…:")
        print("  macOS/Linux: curl -fsSL https://ollama.com/install.sh | sh")
        print("  æˆ–è®¿é—®: https://ollama.com/download")
        print()
        print("å®‰è£…åè¿è¡Œ:")
        print("  ollama pull ministral-3:8b")
        print()
        sys.exit(1)

    # æ£€æŸ¥æ¨¡å‹
    model = os.environ.get("OLLAMA_MODEL", DEFAULT_MODEL)

    # è·å–ç”¨æˆ·è¾“å…¥
    if len(sys.argv) > 1:
        user_note = " ".join(sys.argv[1:])
    else:
        print("è¯·è¾“å…¥ä»Šå¤©çš„ä¸‰ä¹¦å¿ƒå¾—ï¼ˆ300-800å­—ï¼‰ï¼š")
        print("ï¼ˆå¯ä»¥åŒ…å«ä½ å¯¹ã€Šå­™å­ã€‹ã€Šèµ„æ²»ã€‹ã€Šåœ£ç»ã€‹ä»»æ„ä¸€éƒ¨çš„æ€è€ƒï¼‰")
        print()
        user_note = input("> ")

    if not user_note.strip():
        print("âŒ å¿ƒå¾—ä¸èƒ½ä¸ºç©º")
        sys.exit(1)

    print()
    print(f"ğŸ“ æ”¶åˆ°å¿ƒå¾— ({len(user_note)} å­—)")
    print()

    # ä¿å­˜åŸå§‹å¿ƒå¾—
    draft_path = save_draft(user_note)
    print(f"âœ… åŸå§‹å¿ƒå¾—å·²ä¿å­˜: {draft_path.relative_to(REPO_ROOT)}")
    print()

    # ç”ŸæˆAIæ³¨ç–
    annotation, metadata = generate_annotation(user_note, model)

    # ä¿å­˜æ³¨ç–
    annotation_path = save_annotation(annotation, metadata)
    print()
    print(f"âœ… AIæ³¨ç–å·²ç”Ÿæˆ: {annotation_path.relative_to(REPO_ROOT)}")
    print(f"ğŸ“Š è¾“å‡ºé•¿åº¦: {metadata['output_length']} å­—")
    print(f"ğŸ¤– æ¨¡å‹: {metadata['model']} (æœ¬åœ°)")
    print()

    # é¢„è§ˆ
    print("=" * 70)
    print("ğŸ“– æ³¨ç–é¢„è§ˆï¼ˆå‰500å­—ï¼‰ï¼š")
    print("=" * 70)
    preview = annotation[:500]
    print(preview)
    if len(annotation) > 500:
        print("\n... (çœç•¥å‰©ä½™å†…å®¹)")
    print()

    # è¯¢é—®æ˜¯å¦æäº¤
    print("=" * 70)
    print("ğŸ’¾ æ˜¯å¦è‡ªåŠ¨æäº¤åˆ°Gitï¼Ÿ(y/n)")
    choice = input("> ").lower()

    if choice in ['y', 'yes', 'æ˜¯']:
        print()
        print("ğŸš€ æ­£åœ¨æäº¤...")

        os.chdir(REPO_ROOT)
        os.system("git add three-books-ai-annotations/ books-ai-publishing/drafts/")

        commit_msg = f"docs: Daily annotation {datetime.now().strftime('%Y-%m-%d')} (Ministral-3 local)"
        os.system(f'git commit -m "{commit_msg}"')

        print()
        print("æ˜¯å¦æ¨é€åˆ°GitHubï¼Ÿ(y/n)")
        push_choice = input("> ").lower()

        if push_choice in ['y', 'yes', 'æ˜¯']:
            os.system("git push origin main")
            print()
            print("âœ… å·²æ¨é€åˆ°GitHub!")
        else:
            print()
            print("âœ… å·²æäº¤åˆ°æœ¬åœ°ï¼Œç¨åå¯è¿è¡Œ 'git push' æ¨é€")
    else:
        print()
        print("âœ… å·²ç”Ÿæˆæ³¨ç–æ–‡ä»¶ï¼Œå¯ç¨åæ‰‹åŠ¨æäº¤")

    print()
    print("=" * 70)
    print("ğŸ‰ å®Œæˆï¼ç»§ç»­ä¿æŒæ¯æ—¥å¿ƒå¾—ï¼Œ7å¹´åè§è¯ä¼ ä¸–ä¹‹ä½œã€‚")
    print("=" * 70)


if __name__ == "__main__":
    main()
